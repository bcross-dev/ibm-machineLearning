{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regression-based Rating Score Prediction using Embedding Features**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous lab, you have trained a neural network to predict the user-item interactions while simultaneously extracting the user and item embedding features. In the neural network, extends this by using  two embedding vectors as an input into a Neural Network to predict the rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/rating_regression.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another way to make rating predictions is to use the embedding as an input to a neural network by aggregating them into a single feature vector as input data `X`. \n",
    "\n",
    "With the interaction label `Y` such as a rating score or an enrollment mode, we can build our other standalone predictive models to approximate the mapping from `X` to `Y`, as shown in the above flowchart.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be given the course interaction feature vectors as input data `X` and consider label `Y` as the numerical rating scores. As such, we turn the recommender system into a common regression task and you can apply what you have learned about regression modeling to predict the ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build regression models to predict ratings using the combined embedding vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and setup lab environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install and import required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-learn==1.0.2) (1.7.3)\n",
      "Collecting joblib>=0.11 (from scikit-learn==1.0.2)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn==1.0.2)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed joblib-1.3.1 scikit-learn-1.0.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# also set a random state\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88, got 80\n",
      "  return f(*args, **kwds)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n",
    "user_emb_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/user_embeddings.csv\"\n",
    "item_emb_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/course_embeddings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset is the rating dataset that contains a user-item interaction matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rating_df = pd.read_csv(rating_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating\n",
       "0  1889878    CC0101EN     3.0\n",
       "1  1342067    CL0101EN     3.0\n",
       "2  1990814  ML0120ENv3     3.0\n",
       "3   380098    BD0211EN     3.0\n",
       "4   779563    DS0101EN     3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above data, the user and item are just ids, let's substitute them by their embedding vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load user embeddings\n",
    "user_emb = pd.read_csv(user_emb_url)\n",
    "# Load item embeddings\n",
    "item_emb = pd.read_csv(item_emb_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>UFeature0</th>\n",
       "      <th>UFeature1</th>\n",
       "      <th>UFeature2</th>\n",
       "      <th>UFeature3</th>\n",
       "      <th>UFeature4</th>\n",
       "      <th>UFeature5</th>\n",
       "      <th>UFeature6</th>\n",
       "      <th>UFeature7</th>\n",
       "      <th>UFeature8</th>\n",
       "      <th>UFeature9</th>\n",
       "      <th>UFeature10</th>\n",
       "      <th>UFeature11</th>\n",
       "      <th>UFeature12</th>\n",
       "      <th>UFeature13</th>\n",
       "      <th>UFeature14</th>\n",
       "      <th>UFeature15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>0.080721</td>\n",
       "      <td>-0.129561</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>0.030231</td>\n",
       "      <td>0.082691</td>\n",
       "      <td>-0.004176</td>\n",
       "      <td>-0.003480</td>\n",
       "      <td>0.091464</td>\n",
       "      <td>-0.040247</td>\n",
       "      <td>0.018958</td>\n",
       "      <td>-0.153328</td>\n",
       "      <td>-0.090143</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>-0.058721</td>\n",
       "      <td>0.057929</td>\n",
       "      <td>-0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>-0.112781</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>-0.038382</td>\n",
       "      <td>0.068037</td>\n",
       "      <td>0.114949</td>\n",
       "      <td>0.104128</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.064832</td>\n",
       "      <td>0.165857</td>\n",
       "      <td>-0.004384</td>\n",
       "      <td>0.053257</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.056684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>-0.072627</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.133306</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>-0.156026</td>\n",
       "      <td>0.039269</td>\n",
       "      <td>0.042195</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>-0.115989</td>\n",
       "      <td>0.031158</td>\n",
       "      <td>0.102021</td>\n",
       "      <td>-0.020601</td>\n",
       "      <td>0.116488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>-0.034870</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.077406</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>0.032846</td>\n",
       "      <td>-0.060944</td>\n",
       "      <td>0.112384</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>-0.068545</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.063962</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>0.018072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>0.106414</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.017211</td>\n",
       "      <td>-0.042277</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.056732</td>\n",
       "      <td>0.074610</td>\n",
       "      <td>-0.019367</td>\n",
       "      <td>-0.031341</td>\n",
       "      <td>0.064896</td>\n",
       "      <td>-0.048158</td>\n",
       "      <td>-0.047309</td>\n",
       "      <td>-0.007544</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>-0.032287</td>\n",
       "      <td>-0.083983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  UFeature0  UFeature1  UFeature2  UFeature3  UFeature4  UFeature5  \\\n",
       "0  1889878   0.080721  -0.129561   0.087998   0.030231   0.082691  -0.004176   \n",
       "1  1342067   0.068047  -0.112781   0.045208  -0.007570  -0.038382   0.068037   \n",
       "2  1990814   0.124623   0.012910  -0.072627   0.049935   0.020158   0.133306   \n",
       "3   380098  -0.034870   0.000715   0.077406   0.070311  -0.043007  -0.035446   \n",
       "4   779563   0.106414  -0.001887  -0.017211  -0.042277  -0.074953  -0.056732   \n",
       "\n",
       "   UFeature6  UFeature7  UFeature8  UFeature9  UFeature10  UFeature11  \\\n",
       "0  -0.003480   0.091464  -0.040247   0.018958   -0.153328   -0.090143   \n",
       "1   0.114949   0.104128  -0.034401   0.004011    0.064832    0.165857   \n",
       "2  -0.035366  -0.156026   0.039269   0.042195    0.014695   -0.115989   \n",
       "3   0.032846  -0.060944   0.112384   0.002114    0.090660   -0.068545   \n",
       "4   0.074610  -0.019367  -0.031341   0.064896   -0.048158   -0.047309   \n",
       "\n",
       "   UFeature12  UFeature13  UFeature14  UFeature15  \n",
       "0    0.082830   -0.058721    0.057929   -0.001472  \n",
       "1   -0.004384    0.053257    0.014308    0.056684  \n",
       "2    0.031158    0.102021   -0.020601    0.116488  \n",
       "3    0.008967    0.063962    0.052347    0.018072  \n",
       "4   -0.007544    0.010474   -0.032287   -0.083983  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>CFeature0</th>\n",
       "      <th>CFeature1</th>\n",
       "      <th>CFeature2</th>\n",
       "      <th>CFeature3</th>\n",
       "      <th>CFeature4</th>\n",
       "      <th>CFeature5</th>\n",
       "      <th>CFeature6</th>\n",
       "      <th>CFeature7</th>\n",
       "      <th>CFeature8</th>\n",
       "      <th>CFeature9</th>\n",
       "      <th>CFeature10</th>\n",
       "      <th>CFeature11</th>\n",
       "      <th>CFeature12</th>\n",
       "      <th>CFeature13</th>\n",
       "      <th>CFeature14</th>\n",
       "      <th>CFeature15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>-0.005238</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>-0.005274</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.015081</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>-0.035495</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>-0.032560</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>-0.006218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>-0.008611</td>\n",
       "      <td>0.028041</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>-0.017981</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>-0.037610</td>\n",
       "      <td>-0.019397</td>\n",
       "      <td>-0.025682</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.045343</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.019429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>-0.027649</td>\n",
       "      <td>-0.007484</td>\n",
       "      <td>-0.059451</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>-0.012695</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>-0.010450</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.044454</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>-0.007559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>-0.011972</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>-0.015548</td>\n",
       "      <td>-0.007540</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>-0.005700</td>\n",
       "      <td>-0.006068</td>\n",
       "      <td>-0.005792</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>-0.023480</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>-0.023115</td>\n",
       "      <td>-0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>-0.005487</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.010015</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.017598</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.021283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item  CFeature0  CFeature1  CFeature2  CFeature3  CFeature4  \\\n",
       "0    CC0101EN   0.009657  -0.005238  -0.004098   0.016303  -0.005274   \n",
       "1    CL0101EN  -0.008611   0.028041   0.021899  -0.001465   0.006900   \n",
       "2  ML0120ENv3   0.027439  -0.027649  -0.007484  -0.059451   0.003972   \n",
       "3    BD0211EN   0.020163  -0.011972  -0.003714  -0.015548  -0.007540   \n",
       "4    DS0101EN   0.006399   0.000492   0.005640   0.009639  -0.005487   \n",
       "\n",
       "   CFeature5  CFeature6  CFeature7  CFeature8  CFeature9  CFeature10  \\\n",
       "0  -0.000361  -0.015081  -0.012229   0.015686   0.008401   -0.035495   \n",
       "1  -0.017981   0.010899  -0.037610  -0.019397  -0.025682   -0.000620   \n",
       "2   0.020496  -0.012695   0.036138   0.019965   0.018686   -0.010450   \n",
       "3   0.014847  -0.005700  -0.006068  -0.005792  -0.023036    0.015999   \n",
       "4  -0.000590  -0.010015  -0.001514  -0.017598   0.003590    0.016799   \n",
       "\n",
       "   CFeature11  CFeature12  CFeature13  CFeature14  CFeature15  \n",
       "0    0.009381   -0.032560   -0.007292    0.000966   -0.006218  \n",
       "1    0.038803    0.000196   -0.045343    0.012863    0.019429  \n",
       "2   -0.050011    0.013845   -0.044454   -0.001480   -0.007559  \n",
       "3   -0.023480    0.015469    0.022221   -0.023115   -0.001785  \n",
       "4    0.002732    0.005162    0.015031   -0.000877   -0.021283  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge user embedding features\n",
    "user_emb_merged = pd.merge(rating_df, user_emb, how='left', left_on='user', right_on='user').fillna(0)\n",
    "# Merge course embedding features\n",
    "merged_df = pd.merge(user_emb_merged, item_emb, how='left', left_on='item', right_on='item').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>UFeature0</th>\n",
       "      <th>UFeature1</th>\n",
       "      <th>UFeature2</th>\n",
       "      <th>UFeature3</th>\n",
       "      <th>UFeature4</th>\n",
       "      <th>UFeature5</th>\n",
       "      <th>UFeature6</th>\n",
       "      <th>...</th>\n",
       "      <th>CFeature6</th>\n",
       "      <th>CFeature7</th>\n",
       "      <th>CFeature8</th>\n",
       "      <th>CFeature9</th>\n",
       "      <th>CFeature10</th>\n",
       "      <th>CFeature11</th>\n",
       "      <th>CFeature12</th>\n",
       "      <th>CFeature13</th>\n",
       "      <th>CFeature14</th>\n",
       "      <th>CFeature15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.080721</td>\n",
       "      <td>-0.129561</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>0.030231</td>\n",
       "      <td>0.082691</td>\n",
       "      <td>-0.004176</td>\n",
       "      <td>-0.003480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015081</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>-0.035495</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>-0.032560</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>-0.006218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>-0.112781</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>-0.038382</td>\n",
       "      <td>0.068037</td>\n",
       "      <td>0.114949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>-0.037610</td>\n",
       "      <td>-0.019397</td>\n",
       "      <td>-0.025682</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.045343</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.019429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>-0.072627</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.133306</td>\n",
       "      <td>-0.035366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012695</td>\n",
       "      <td>0.036138</td>\n",
       "      <td>0.019965</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>-0.010450</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>0.013845</td>\n",
       "      <td>-0.044454</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>-0.007559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.034870</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.077406</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>0.032846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005700</td>\n",
       "      <td>-0.006068</td>\n",
       "      <td>-0.005792</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>-0.023480</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>-0.023115</td>\n",
       "      <td>-0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.106414</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.017211</td>\n",
       "      <td>-0.042277</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.056732</td>\n",
       "      <td>0.074610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010015</td>\n",
       "      <td>-0.001514</td>\n",
       "      <td>-0.017598</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>-0.021283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating  UFeature0  UFeature1  UFeature2  UFeature3  \\\n",
       "0  1889878    CC0101EN     3.0   0.080721  -0.129561   0.087998   0.030231   \n",
       "1  1342067    CL0101EN     3.0   0.068047  -0.112781   0.045208  -0.007570   \n",
       "2  1990814  ML0120ENv3     3.0   0.124623   0.012910  -0.072627   0.049935   \n",
       "3   380098    BD0211EN     3.0  -0.034870   0.000715   0.077406   0.070311   \n",
       "4   779563    DS0101EN     3.0   0.106414  -0.001887  -0.017211  -0.042277   \n",
       "\n",
       "   UFeature4  UFeature5  UFeature6  ...  CFeature6  CFeature7  CFeature8  \\\n",
       "0   0.082691  -0.004176  -0.003480  ...  -0.015081  -0.012229   0.015686   \n",
       "1  -0.038382   0.068037   0.114949  ...   0.010899  -0.037610  -0.019397   \n",
       "2   0.020158   0.133306  -0.035366  ...  -0.012695   0.036138   0.019965   \n",
       "3  -0.043007  -0.035446   0.032846  ...  -0.005700  -0.006068  -0.005792   \n",
       "4  -0.074953  -0.056732   0.074610  ...  -0.010015  -0.001514  -0.017598   \n",
       "\n",
       "   CFeature9  CFeature10  CFeature11  CFeature12  CFeature13  CFeature14  \\\n",
       "0   0.008401   -0.035495    0.009381   -0.032560   -0.007292    0.000966   \n",
       "1  -0.025682   -0.000620    0.038803    0.000196   -0.045343    0.012863   \n",
       "2   0.018686   -0.010450   -0.050011    0.013845   -0.044454   -0.001480   \n",
       "3  -0.023036    0.015999   -0.023480    0.015469    0.022221   -0.023115   \n",
       "4   0.003590    0.016799    0.002732    0.005162    0.015031   -0.000877   \n",
       "\n",
       "   CFeature15  \n",
       "0   -0.006218  \n",
       "1    0.019429  \n",
       "2   -0.007559  \n",
       "3   -0.001785  \n",
       "4   -0.021283  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can combine the user features (the column labels starting with `UFeature` and item features (the column labels starting with `CFeature`. In machine learning, there are many ways to aggregate two feature vectors such as element-wise add, multiply, max/min, average, etc. Here we simply add the two sets of feature columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature0</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>Feature10</th>\n",
       "      <th>Feature11</th>\n",
       "      <th>Feature12</th>\n",
       "      <th>Feature13</th>\n",
       "      <th>Feature14</th>\n",
       "      <th>Feature15</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090378</td>\n",
       "      <td>-0.134799</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.077417</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>-0.018561</td>\n",
       "      <td>0.079236</td>\n",
       "      <td>-0.024561</td>\n",
       "      <td>0.027359</td>\n",
       "      <td>-0.188823</td>\n",
       "      <td>-0.080762</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>-0.066013</td>\n",
       "      <td>0.058894</td>\n",
       "      <td>-0.007689</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059437</td>\n",
       "      <td>-0.084740</td>\n",
       "      <td>0.067107</td>\n",
       "      <td>-0.009036</td>\n",
       "      <td>-0.031482</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.125847</td>\n",
       "      <td>0.066517</td>\n",
       "      <td>-0.053798</td>\n",
       "      <td>-0.021671</td>\n",
       "      <td>0.064212</td>\n",
       "      <td>0.204660</td>\n",
       "      <td>-0.004188</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.027170</td>\n",
       "      <td>0.076114</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152061</td>\n",
       "      <td>-0.014739</td>\n",
       "      <td>-0.080112</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>0.153802</td>\n",
       "      <td>-0.048061</td>\n",
       "      <td>-0.119888</td>\n",
       "      <td>0.059234</td>\n",
       "      <td>0.060882</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>-0.166000</td>\n",
       "      <td>0.045002</td>\n",
       "      <td>0.057566</td>\n",
       "      <td>-0.022081</td>\n",
       "      <td>0.108929</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014707</td>\n",
       "      <td>-0.011257</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.054763</td>\n",
       "      <td>-0.050547</td>\n",
       "      <td>-0.020599</td>\n",
       "      <td>0.027146</td>\n",
       "      <td>-0.067012</td>\n",
       "      <td>0.106593</td>\n",
       "      <td>-0.020921</td>\n",
       "      <td>0.106658</td>\n",
       "      <td>-0.092025</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.086183</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112812</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>-0.011572</td>\n",
       "      <td>-0.032638</td>\n",
       "      <td>-0.080440</td>\n",
       "      <td>-0.057321</td>\n",
       "      <td>0.064595</td>\n",
       "      <td>-0.020880</td>\n",
       "      <td>-0.048939</td>\n",
       "      <td>0.068486</td>\n",
       "      <td>-0.031359</td>\n",
       "      <td>-0.044577</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>-0.033164</td>\n",
       "      <td>-0.105266</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n",
       "0  0.090378 -0.134799  0.083900  0.046534  0.077417 -0.004537 -0.018561   \n",
       "1  0.059437 -0.084740  0.067107 -0.009036 -0.031482  0.050057  0.125847   \n",
       "2  0.152061 -0.014739 -0.080112 -0.009516  0.024130  0.153802 -0.048061   \n",
       "3 -0.014707 -0.011257  0.073692  0.054763 -0.050547 -0.020599  0.027146   \n",
       "4  0.112812 -0.001395 -0.011572 -0.032638 -0.080440 -0.057321  0.064595   \n",
       "\n",
       "   Feature7  Feature8  Feature9  Feature10  Feature11  Feature12  Feature13  \\\n",
       "0  0.079236 -0.024561  0.027359  -0.188823  -0.080762   0.050271  -0.066013   \n",
       "1  0.066517 -0.053798 -0.021671   0.064212   0.204660  -0.004188   0.007914   \n",
       "2 -0.119888  0.059234  0.060882   0.004244  -0.166000   0.045002   0.057566   \n",
       "3 -0.067012  0.106593 -0.020921   0.106658  -0.092025   0.024436   0.086183   \n",
       "4 -0.020880 -0.048939  0.068486  -0.031359  -0.044577  -0.002381   0.025505   \n",
       "\n",
       "   Feature14  Feature15  rating  \n",
       "0   0.058894  -0.007689     3.0  \n",
       "1   0.027170   0.076114     3.0  \n",
       "2  -0.022081   0.108929     3.0  \n",
       "3   0.029232   0.016287     3.0  \n",
       "4  -0.033164  -0.105266     3.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_feautres = [f\"UFeature{i}\" for i in range(16)]\n",
    "c_features = [f\"CFeature{i}\" for i in range(16)]\n",
    "\n",
    "user_embeddings = merged_df[u_feautres]\n",
    "course_embeddings = merged_df[c_features]\n",
    "ratings = merged_df['rating']\n",
    "\n",
    "# Aggregate the two feature columns using element-wise add\n",
    "regression_dataset = user_embeddings + course_embeddings.values\n",
    "regression_dataset.columns = [f\"Feature{i}\" for i in range(16)]\n",
    "regression_dataset['rating'] = ratings\n",
    "regression_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have built the input dataset `X` and the output vector `y`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (233306, 16), Output data shape: (233306,)\n"
     ]
    }
   ],
   "source": [
    "X = regression_dataset.iloc[:, :-1]\n",
    "y = regression_dataset.iloc[:, -1]\n",
    "print(f\"Input data shape: {X.shape}, Output data shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK: Perform regression on the interaction dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our input data `X` and output `y` are ready, let's build regression models to map X to y and predict ratings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an online course system, we may consider the `Completion` mode to be `larger` than the `Audit` mode as a learner needs to put more efforts towards completion.  Now if we treat it as a regression problem,  we would expect the regression model to output ratings ranging from 2.0 to 3.0. To interpret regression model output, we can treat values closer to 2.0 as `Audit` and values closer to 3.0 as `Completion`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may use `sklearn` to train and evaluate various regression models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: First split dataset into training and testing datasets_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state = rs, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "Use `train_test_split()` to split dataset into training and testing datasets.  Use `X, y` as input dataset and output vector. Don't forget to specify `random_state = rs` and `test_size=0.3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Create a basic linear regression model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "You can call `linear_model.Ridge()` method and specify `alpha=0.2` ( it's controlling regularization) in the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Train the basic regression model with training data_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "You can call `model.fit()` method with `X_train, y_train` parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Evaluate the basic regression model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04395331072990272"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "predictions = model.predict(x_test)\n",
    "mean_squared_error(y_test, predictions)\n",
    "### The main evaluation metric is RMSE but you may use other metrics as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "You can call `model.predict()` method with `X_test` parameter to get model predictions. Then use `mean_squared_error()` with `y_test, your_predictions` parameters to calculate the RMSE. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Try different regression models such as Ridge, Lasso, ElasticNet and tune their hyperparameters to see which one has the best performance_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "def reg_model(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    print(\"%s: %s\" % (model, mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.2): 0.043953312914868446\n"
     ]
    }
   ],
   "source": [
    "ridge_model = linear_model.Ridge(alpha = 0.2)\n",
    "reg_model(ridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.3): 0.044252687736496245\n"
     ]
    }
   ],
   "source": [
    "lasso_model = linear_model.Lasso(alpha = 0.3)\n",
    "reg_model(lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 0.1\n",
    "alphas = list(np.arange(n, 1+n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043953321973382"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge\n",
    "\n",
    "params_grid = {'alpha': alphas}\n",
    "\n",
    "ridgeModel = GridSearchCV(estimator = linear_model.Ridge(random_state = rs),\n",
    "                         param_grid = params_grid,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = 5)\n",
    "\n",
    "ridgeModel.fit(x_train, y_train)\n",
    "predictions = ridgeModel.predict(x_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=123, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeModel.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044252687736496245"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso\n",
    "\n",
    "params_grid = {'alpha': alphas}\n",
    "\n",
    "lassoModel = GridSearchCV(estimator = linear_model.Lasso(random_state = rs),\n",
    "                         param_grid = params_grid,\n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = 5)\n",
    "\n",
    "lassoModel.fit(x_train, y_train)\n",
    "predictions = lassoModel.predict(x_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoModel.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044252687736496245"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Elastic Net\n",
    "\n",
    "params_grid = {'alpha': alphas,\n",
    "              'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "\n",
    "elasticModel = GridSearchCV(estimator = linear_model.ElasticNet(random_state = rs),\n",
    "                            param_grid = params_grid,\n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                           cv = 5)\n",
    "\n",
    "elasticModel.fit(x_train, y_train)\n",
    "predictions = elasticModel.predict(x_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=123, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticModel.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['KNN Item', 'NMF', 'NN ridge', 'NN lasso', 'NN elastic net']\n",
    "y = [0.050, 0.192, 0.043953, 0.044253, 0.044253]\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.title('Model RMSE comparison')\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you have built regression models to predict numerical course ratings using the embedding feature vectors extracted from neural networks. In the next lab, we can treat the prediction problem as a classification problem as rating only has two categorical values so classification can be a more natural problem statement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2021-10-25|1.0|Yan|Created the initial version|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
